{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["hjuN4pILaaNx"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 1. Import libraries:"],"metadata":{"id":"n3SHP0CLZy7w"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"2ezc72nuB1Pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imported Libraries\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.patches as mpatches\n","import time\n","from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, RandomizedSearchCV\n","from imblearn.over_sampling import SMOTE\n","\n","# Classifier Libraries\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","import collections\n","\n","from sklearn.pipeline import make_pipeline\n","from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n","from imblearn.under_sampling import NearMiss\n","from imblearn.metrics import classification_report_imbalanced\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n","from collections import Counter\n","from sklearn.model_selection import KFold, StratifiedKFold"],"metadata":{"id":"WPOLhe0BZ39L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Import data:"],"metadata":{"id":"OX9Rx_UtaXAz"}},{"cell_type":"code","source":["dataset_path = \"/content/drive/MyDrive/UIT Projects/Khai thác dữ liệu/source/creditcard_dataset.csv\""],"metadata":{"id":"TXoJgnl6ZsOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(dataset_path)\n","df.head(5)"],"metadata":{"id":"GLg1PLoLaIM6","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"error","timestamp":1681831926212,"user_tz":-420,"elapsed":2131,"user":{"displayName":"Nhựt Phạm Thanh","userId":"11631745287585277862"}},"outputId":"9dcf4a40-49b6-4466-b76e-e298a357a1f6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2676855f346f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UIT Projects/Khai thác dữ liệu/source/creditcard_dataset.csv'"]}]},{"cell_type":"code","source":["df.keys()"],"metadata":{"id":"DR40QW-iaRBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_value_groups = df['Class'].value_counts()\n","number_of_rows = len(df)\n","\n","print('No Frauds', round(class_value_groups[0]/number_of_rows * 100, 2), '% of the dataset')\n","print('Frauds', round(class_value_groups[1]/number_of_rows * 100, 2), '% of the dataset')"],"metadata":{"id":"mXIl_vOiaudL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Pre-processing data:"],"metadata":{"id":"Ge1PFLYoZ_2O"}},{"cell_type":"markdown","source":["#### 3.1. Scaling and Distributing:"],"metadata":{"id":"hjuN4pILaaNx"}},{"cell_type":"markdown","source":["Scale columns: Time, Amount"],"metadata":{"id":"vUr-jP00cIGA"}},{"cell_type":"code","source":["rob_scaler = RobustScaler()\n","\n","scaled_amount = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n","scaled_time = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n","\n","df.drop(['Time','Amount'], axis=1, inplace=True)\n","\n","df.insert(0, 'scaled_amount', scaled_amount)\n","df.insert(1, 'scaled_time', scaled_time)\n","\n","df.head(5)"],"metadata":{"id":"Dx4N3s4Gaeuy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Split data to train and test"],"metadata":{"id":"DsIZTwqNeZmx"}},{"cell_type":"code","source":["X = df.drop('Class', axis=1)\n","y = df['Class']\n","\n","sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n","\n","for train_index, test_index in sss.split(X, y):\n","    print(\"Train:\", train_index, \"Test:\", test_index)\n","    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n","    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n","\n","original_Xtrain = original_Xtrain.values\n","original_Xtest = original_Xtest.values\n","original_ytrain = original_ytrain.values\n","original_ytest = original_ytest.values\n","\n","# See if both the train and test label distribution are similarly distributed\n","train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n","test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n","print('-' * 100)\n","\n","print('Label Distributions: \\n')\n","print(train_counts_label/ len(original_ytrain))\n","print(test_counts_label/ len(original_ytest))"],"metadata":{"id":"1xoB1Bk7cV2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Training data:"],"metadata":{"id":"icp9dVGXigxk"}},{"cell_type":"markdown","source":["#### 4.1 Simple training with SMOTE:"],"metadata":{"id":"eFocQH7DfolQ"}},{"cell_type":"code","source":["print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n","print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))"],"metadata":{"id":"cCXbLAr0ujdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List to append the score and then find the average\n","accuracy_lst = []\n","precision_lst = []\n","recall_lst = []\n","f1_lst = []\n","auc_lst = []\n","\n","# Classifier with optimal parameters\n","\n","tree_params = {\n","    \"criterion\": [\"gini\", \"entropy\"],\n","    \"max_depth\": list(range(2, 10, 1)),\n","    \"min_samples_leaf\": list(range(2, 10, 1))\n","}\n","rand_grid_tree = RandomizedSearchCV(DecisionTreeClassifier(), tree_params)\n","\n","# Implementing SMOTE Technique\n","# Cross Validating the right way\n","for train, test in sss.split(original_Xtrain, original_ytrain):\n","    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_grid_tree) # SMOTE happens during Cross Validation not before..\n","    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n","\n","    best_est = rand_grid_tree.best_estimator_\n","    prediction = best_est.predict(original_Xtrain[test])\n","\n","    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n","    precision_lst.append(precision_score(original_ytrain[test], prediction))\n","    recall_lst.append(recall_score(original_ytrain[test], prediction))\n","    f1_lst.append(f1_score(original_ytrain[test], prediction))\n","    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n","\n","print('---' * 45)\n","print('')\n","print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n","print(\"precision: {}\".format(np.mean(precision_lst)))\n","print(\"recall: {}\".format(np.mean(recall_lst)))\n","print(\"f1: {}\".format(np.mean(f1_lst)))\n","print('---' * 45)"],"metadata":{"id":"i_Tgi9Dp0-BB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4.2. Training with GA algorithm:\n","\n","\n","\n"],"metadata":{"id":"zKMs_zR4kWMv"}},{"cell_type":"code","source":["class Individual(object):\n","    def __init__(self, chromosome):\n","        self.chromosome = chromosome\n","        self.fitness = self.calculate_fitness()\n","\n","    @classmethod\n","    def create_random_gene(self):\n","        global ALL_GENEs\n","        gene = random.choice(ALL_GENEs)\n","        return gene\n","\n","    @classmethod\n","    def create_random_chromosome(self, chro_len):\n","        global TARGET\n","        chromosome_len = chro_len\n","        chromosome = []\n","        for _ in range(chromosome_len):\n","            random_gene = self.create_random_gene()\n","            chromosome.append(random_gene)\n","        return chromosome\n","\n","    def crossover(self, individual_2):\n","        child_chromosome = []\n","        for gene_of_ind1, gene_of_ind2 in zip(self.chromosome, individual_2.chromosome):\n","            prob = random.random()\n","\n","            if prob < 0.45:\n","                child_chromosome.append(gene_of_ind1)\n","            elif prob < 0.9:\n","                child_chromosome.append(gene_of_ind2)\n","            else:\n","                random_gene = self.create_random_gene()\n","                child_chromosome.append(random_gene)\n","        child = Individual(child_chromosome)\n","        return child\n","\n","    def calculate_fitness(self):\n","        global TARGET\n","        fitness = 0\n","        rf = RandomForestClassifier(criterion= 'entropy', max_depth=6, max_features='log2', n_estimators= 10)\n","\n","        columns_to_train = self.chromosome\n","        X = new_df[columns_to_train].values\n","        Y = new_df['Class'].values\n","\n","        _, F, _, y = train_test_split(X, Y, test_size=0.2)\n","        F_train, F_test, y_train, y_test = train_test_split(F, y, test_size=0.2)\n","\n","        rf.fit(F_train, y_train)\n","        # evaluating\n","        y_pred_test = rf.predict(F_test)\n","        test_score = accuracy_score(y_test, y_pred_test)\n","\n","        fitness = test_score\n","        return fitness"],"metadata":{"id":"HTVcFDqVkaWA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Evaluating:"],"metadata":{"id":"gc5p_fxtno_q"}},{"cell_type":"code","source":[],"metadata":{"id":"VHPgT-s4nrVB"},"execution_count":null,"outputs":[]}]}